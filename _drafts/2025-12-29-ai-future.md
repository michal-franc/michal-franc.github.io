---
layout: d3post
title: Software Engineer 2026 Transformation
date: 2025-12-30 07:00
author: Michal Franc
comments: true
categories: [Career]
tags: [ai, career]
image: logo_ai_2026.png
series:
permalink: /blog/ai-2026/
summary: AI 2026 Software Engineering career transformation
---

```ad-quote
_Roy Amara_
We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.
[Wikipedia](https://en.wikipedia.org/wiki/Roy_Amara)
```

We are in 2026 and I am not 100% sure were we are headed as a industry (software engineering) when it comes to AI and LLMs but in order to prepare for the future I have some thoughts and `bets`. 

By `bets` I mean. As staff+ engineer I need to have an opinion and strategy on how to evolve the organisation I lead. Of course this is just an `opinion` based on my current knowledge, everything can change with time - we will see (**it is important to be adaptable**).

So here it is my current view for 2026 when it coems to AI/LLMs, IT and software engineering.

But first bold statement to get the elephant out of the room: **Software Engineering is not going anywhere and will evolve to even bigger opportunity.**

```ad-note
_TL;DR;_
- There are 3 AI camps - we are `doomed`, AI will `fail`, AI will `transform` the market
- I'm in the transformation camp
- The core of software engineering was always - impact and value generation
- Transformation towards Product engineering and Systems Thinking
- Transformation is nothing new in IT It will be a source of opportunities
- Being early adopter of technology or paradigm shift == big profits
- What it means for junior engineers? mid engineers? senior engineers? staff+ engineers?
```
## There are 3 AI camps

**Doomers**
In this scenario, I'm assuming we reach AGI and AI simply replaces us. But looking at recent evaluations, like [METR's assessment of OpenAI's GPT-5.1-Codex-Max](https://evaluations.metr.org/gpt-5-1-codex-max-report/#summary), current LLM systems are still incapable of generating serious problems for us. And if we look at benchmarks like [ARC Prize](https://arcprize.org/), we're still far, far away from reaching AGI, at least based on the way we currently mesure what AGI is. Based on [AI 2027](https://ai-2027.com/) there is also a scenario that we have paradise enabled by AI, but it also implies that the industry as a whole is `gone`.

**AI is a fad**
In the past there were two major [AI winters](https://en.wikipedia.org/wiki/AI_winter). It is possible that another one is just around the corner.  There are alrready experts that argue that LLMs are not AI and are going to take us nowwhere. That the path to AGI requires more breakthroughs. I can't argue with that as I am not an expert in this field all I am interested is on how to use the current generation of AI/LLMs in my field of expertise.

I think we're long past the point where we can assyne that AI is a failure. Based on my experience and people around me there is a lot of utility and value in the current generation of LLMs. I don't think anyone will argue about that. The discussions in my circle are more about - how to use it? What are the good  practices? What will be the new design patterns we should adapt to?

Also based on the [Can AI scaling continue through 2030?](https://epoch.ai/blog/can-ai-scaling-continue-through-2030) it looks like that we will be able to scale AI training runs to 2030. At the moment it looks like there is no major bottleneck apart from "AI is a bubble" burst - which might slow things down. But the "AI bubble" is just a course correction and is more about hype and investmenet promises made to investors not about the usefullness of this technology.

**Transformation**
So when the bubble pops and the dust settles - what will the market look like? I believe AI tools will become just that: _tools_, and the question is how will this transformation look like.

```ad-sidenote
_AI usefullness polarization_

The AI usefulness debate has two teams: "it's broken" and "engineers are dead." Both are wrong. AI is great at some problems, terrible at others. The interesting question is knowing which is which.
```
## Transformation - nothing new in IT

<div markdown="0">
{% include /ai-future/chart-demand.html %}
</div>

This is of course obvious, but the market is _constantly changing_. If you look at the overall employment history of Tech related roles in the US, you see roughly a steady growth. I couldn't find exact data for software engineers, but these roles did follow a similar curve.

Based on this chart we can assume here that demand is growing constantly. But this view hides a lof of complexity. Definining what "software engineering" role is, is simple when we think about generic terms like - building software. But uderneath when we think about programming languages, specfifics skills or practices used in this field - the view gets a lot more complicated.

What the market actually demands shifts constantly - different skills, different eras, different value.

### Programming Languages
<div markdown="0">
{% include /ai-future/chart-languages.html %}
</div>

This shift can be observed in programming language popularity. The [TIOBE index](https://www.tiobe.com/tiobe-index/) shows how languages rise and fall over time. The industry was once dominated by Java, C, and C++. Now Python sits at the top - likely driven by demand in data science and AI.

The growing demand is spread across different programming languages needs based on market needs.

**My personal experience:** The first language I have used commercially at work - was JavaScript with JQuery (old times). Then I moved to C# / .NET world for couple of years.  There was some time with more of Javascript (Angular/Reac), and I moved to write software in Golang, Java, Python or even Lua. These days I mostly write code in C#, Golang, Python.

```ad-sidenote
_Tiobe index vs PYPL index_

I know Tiobe is only one way opinionated way to measure programming language usage. Other approaches like [PYPL](https://pypl.github.io/PYPL.html) sometimes show different data. But both tell the same story: language popularity is fluid. What dominates today won't necessarily dominate tomorrow.
```

### Emerging Skills 
<div markdown="0">
{% include /ai-future/chart-emerging-skills.html %}
</div>

Similar picture does come up in the skills area - from Manual QA to Test Automation, Devops, DevSecOps. A lot of the current demand requires new types of skills that we had to acquire over time.

**My personal experience:** I have started as Sharepoint Developer long time ago, then I jumped into fullstack ASP.NET world. I was a huge advocate of TDD. As the industry changed I was an early adopter of docker and cloud. Even thought i spent a lot of time in C# oriented companies - I have never used Azure but AWS. With time I discovered beatifull world of distributed systems and I focused more on DevOps/SRE oriented work. Today I would consider myself to be a generalist.

### Methodologies
<div markdown="0">
{% include /ai-future/chart-metodologies.html %}
</div>

And last chart methodologies - once we were dominated by waterfall which then change to agile and scrum.

**My personal experience:** I had opportunity to try Waterfall (It wasn't as bat as the current myths portray it). But I entered market with already big ideas like DDD, Agile on the horizon so it was easy to switch over to it.

## Why does transformation happen? Competition → Commoditisation → Innovation
Transformation isn't unique to tech. It's core part of our economic model and arguably part of being human. We evolved in a competitive environment, under constant pressure from natural selection. That same pressure drove us toward collaboration, cooperation, and eventually organising ourselves into societies.  In the market we are in a constant cycle of: **Competition -> Commoditization -> Innovation**

Here is what I mean: A company discovers a new need in the market, creates a product, this brings profit. Other companies see it and start competing. Competition drives down margins, and the product becomes commoditised - meaning it is not special anymore. To escape low margins, you need to innovate. Find novel ideas to create new value. And the cycle repeats.

```ad-sidenote
_What about `monopolies`?_
I know, I know - this is much more complicated and competition is not as clear. There are specific markets dominated by single companies (either whole segment of the market or geographically), and even in the past goverments had to interveene in order to open up the competition as Big players always have an incentive to control competition and the market itself.

One great example from my country was breaking up dominant telecomunications company in Poland to open up the market (which was very succesfull for the economy and the consumers).

But as a principle - competition as one of the main market drivers in general still holds.
```
### Software development was always under transformation pressure
Now, as software engineers, we might think this doesn't apply to us. We are engineers and all of the transformations were driven by innovation and people wanting to do things better. Some of it, sure. Open source is a perfect example of people building better tools because they wanted better tools. But a lot of innovation, was driven by the market.

**Software development process has always been expensive and was considered to be a pain point to get around.** Designing systems, writing code, testing, releasing to production - all of it costs time and money while the specifics of building software was never the _point_. The goal was always to build a product. Software development was a necessary cost to get there.

The market - companies, individual engineers, entire communities - felt pressure or need to innovate to bring the cost of development down. Make the work easier:
- New programming languages made it easier to write code
- Frameworks like the JVM handled memory management so we didn't have to
- Languages like Go and Erlang targeted concurrency as systems grew more complex
- Ruby and Python optimised for productivity and speed of delivery
- Agile innovated around the SDLC process
- Cloud made it simpler to orchestrate complex architectures without owning hardware
- DevOps emerged to bring engineers closer to infrastructure - but only after the cost of both coding and infrastructure engineering dropped enough, and complexity increased enough, to make it worthwhile
 
This was a difficult truth for me to accept. As an engineer, I wanted to believe the craft itself mattered. It took me a time to realise that the market doesn't care about Software Craftmanship or how elegant the code is. Of course this doesn't mean that we can just YOLO with software development but there is a term I like to use called **Good Enough Software** that puts a lot more pressure on Engineering Talent to decide how to develop software in a scalable, maintanable, sustainable way - depending on the context - market, product and organisation you are in.

###  The case of Cloud, Kubernetes - abstracting away complexity
What also emerges from these transformation is that each wave abstracts away complexity and shifts where value is created.

Cloud, and Kubernetes are a good example here. Initially, only the biggest companies could build truly scalable, global products. They had the resources, expertise and infrastructure to do it. But as internet usage grew, more companies wanted the same capabilities. AWS capitalised on this - opening up their way to do it in the form of cloud. But the complexity of these systems kept growing. It still wasn't easy to make them reliable and scalable. So the market responded again: orchestration systems emerged to manage the chaos. And then we got Kubernetes.

I know - Kubernetes is complex. It's not "easy." It's sometimes overused. But here's what it did: it commoditised the ability to build global, scalable, reliable systems. What was once the domain of really Big Companies became accessible to a much broader market. **This shifted where the hard problems lived - and where the value was created.**

This also commoditised the skills needed to build global systems. But the demand was there, so it created opportunity. If you were willing to learn, you could capitalise on the shift. The market rewarded those who adapted. This change also actually opened up the need for new type of skills to a wider market.

### The case of Manual -> Automated -> AI driven testing

<div markdown="0">
{% include /ai-future/chart-testing-transition.html %}
</div>

When I joined the industry, it was typical for testing to be done by a dedicated role. You had developers, and you had testers with two different jobs and clear responsibilities. Then a change happened and the org I was part of Manual QAs to learn programming. This also ment that programmers were told to get better at testing. Microsoft formalised this with the SDET role (Software Development Engineer in Test), explicitly encouraging the move toward automated testing. Eventually, even that role disappeared - absorbed into the broader Software Engineer title.

The organisations I worked with for last 12+ years didn't have a dedicated testing role at all. Testing has become a part of Software Engineering and someones speciality, expertise but not the only thing.

The chart presents here  **Manual QA**  skill in a steady decline. Demand dropped, supply didn't adjust, and the skill became oversupplied. Which led to a drop in value generated by this specific skill. **Test Automation** on the other hands paints a completetly different picture with value generated out of this skill growing througth the years.

**LLMs** will likely transform this area further - but here's the paradox. Manual QAs may actually be better positioned to benefit than test automation engineers. Why? Because the _automation_ part of the skill is exactly what AI will commoditise. What remains valuable is the domain expertise, the attention to detail, the ability to identify what needs testing in the first place. If Manual QAs move toward AI-enabled test development, they bring skills that complement LLMs usage rather than compete with it.

A simple pattern that appears here is:
1. New skill need  emerges → is undersupplied → generates high value
2. People learn new skills → supply grows → value normalises
3. Next shift arrives → previous skills demand lose steam -> and you need to adapt

## Transformation is an opportunity (+ stress and uncertainity)

There are two ways to approach transformation. You can treat it as a risk - a threat to your ability to generate value, a force that might make your skills obsolete. Or you can look at it as an opportunity. I prefer to look at it from a opportunity angle.

Of course its not easy to just say - well adapt - learn new skills. I am almost 40, I don't have the same energy which I had in my 20s. By saying `just treat is as opportunity` I'm not being an asshole or a smartass. I really do understand this is stressful. It's not easy to just "adapt" or "learn new skills" when you've spent years building expertise that suddenly can potentially become less valuable or no longer a thing that differentiaties you on the market. But I don't think there is anything else we can do about it. The market will just do its own thing - and force us to transform.

This opportunity is also a bit `fragile` as usually its the early or late adopters that start using new practice or skill and unclock new productivity or value before everyone else. This boost doesn't last for long . Adoption spreads, best practices develop, tooling matures, and what was once an a new things becomes the baseline. 

It can also be risky as when you are an early adopter you have no idea if this specific new wave or hype will stay and develop to something more serious. The amount of innovation and changes that are happening now around AIs and LLMs makes it difficult to decide if its stable or worhty endevour. Personally my instict tells me AI is here to stay and will be a huge transformative factor so I need to keep up. But the market has always rewarded people who take a risk. Not reckless risk - a calculated one.

```ad-sidenote
_You should always have some risky bets in your career_  

Think of it like investing. You diversify. Some skills you go deep on, hands-on. Others you keep an eye on, waiting for the right moment to commit. Not every bet pays off—but having no risky bets at all is the riskiest position of all.
```

**I believe AI will transform our industry. It will make us more productive, more impactful, and ultimately more rewarded by the businesses we work for. But to benefit from this shift, you'll need to transform yourself. You'll need to become a different type of engineer.**
 
```ad-note
_IT is in a pole position_

Being in tech means you're in pole position to see what's coming. We're one of the first industries adopting AI at scale. That puts us in the early adopter bracket of a technology shift that will eventually hit every industry. A lot of sectors will face this challenge in 5–10 years. By then, we'll have already lived through it and experienced it, which will open doors to many places not only related to Tech/IT.
```
## AI / LLMs transformation

Before we can jump into some conclusions or advices on how the next transformations might look like, lets get some things stratgh first.
### Software engineering was never only about coding

<div markdown="0">
{% include /ai-future/chart-system-thinking.html %}
</div>

The ability to write code was always a tool- not the goal in itself. Software engineering has always been about building things and solving problems that humans face. All economic activity is ultimately driven by human needs, and our job is to figure out and build systems to address them.

The learning model from the past put a lot of emphasis on coding and computer science early in the careerl. It was usually the first step that the engineers of my generation got hired for.  But as your career progresses, you realise that writing code is just part of your job.

There is a lot of time spent on designing systems, figuring out trade-offs. Communicating with stakeholders, team members or even customers. Planning the work. Advocating for features and changes. Reviewing code or ideas. Or even figuring out how to be effective in the organisation by navigating internall processes as every company is usually different.

The code is just part of the job and it was always bigger than that. And **this is a great news, it means Software Engineering will not dissappear**.

```ad-sidenote
_Autocomplete didn't make us 10x productive_

I remember when autocomplete was becoming popular. There was this feeling that we'd all become much more productive. But it turned out writing code was only a part of the job. There were benefits but autocomplete was was not as transformative as a lot of people assumed. The bottleneck was never the coding speed or coding correctness.
```

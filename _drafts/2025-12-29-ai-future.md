---
layout: d3post
title: AI 2026 and Software Engineering
date: 2025-12-30 07:00
author: Michal Franc
comments: true
categories: [Career]
tags: [ai, career]
image: 
series:
permalink: /blog/ai-2026/
summary: AI 2026 Software Engineering career transformation
---

```ad-quote
_Roy Amara_
We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.
[Wikipedia](https://en.wikipedia.org/wiki/Roy_Amara)
```

We are in 2026 and I am not 100% sure were we are headed as a industry (software engineering) when it comes to AI and LLMs but in order to prepare for the future I have some thoughts and `bets`. 

By `bets` I mean. As staff+ engineer I need to have an opinion and strategy on how to evolve the organisation I lead. Of course this is just an `opinion` based on my current knowledge, everything can change with time - we will see (**it is important to be adaptable**).

So here it is my current view for 2026 when it coems to AI/LLMs, IT and software engineering.

```ad-note
_TL;DR;_
- There are 3 AI camps - we are `doomed`, AI will `fail`, AI will `transform` the market
- I'm in the transformation camp
- The core of software engineering was always - impact and value generation
- Transformation towards Product engineering and Systems Thinking
- Transformation is nothing new in IT It will be a source of opportunities
- Being early adopter of technology or paradigm shift == big profits
- What it means for junior engineers? mid engineers? senior engineers? staff+ engineers?
```
## There are 3 AI camps

**We are Doomed.**
In this scenario, I'm assuming we reach AGI and AI simply replaces us. But looking at recent evaluations, like [METR's assessment of OpenAI's GPT-5.1-Codex-Max](https://evaluations.metr.org/gpt-5-1-codex-max-report/#summary), current LLM systems are still incapable of generating serious problems for us. And if we look at benchmarks like [ARC Prize](https://arcprize.org/), we're still far, far away from reaching AGI, at least based on the way we currently mesure what AGI is. Based on [AI 2027](https://ai-2027.com/) there is also a scenario that we have paradise enabled by AI, but it also implies that the industry as a whole is `gone`.

**AI is a fad that will fail.**
In the past there were two major [AI winters](https://en.wikipedia.org/wiki/AI_winter). It is possible that another one is just around the corner.  There are alrready experts that argue that LLMs are not AI and are going to take us nowwhere. That the path to AGI requires more breakthroughs. I can't argue with that as I am not an expert in this field all I am interested is on how to use the current generation of AI/LLMs in my field of expertise.

I think we're long past the point where we can assyne that AI is a failure. Based on my experience and people around me there is a lot of utility and value in the current generation of LLMs. I don't think anyone will argue about that. The discussions in my circle are more about - how to use it? What are the good  practices? What will be the new design patterns we should adapt to?

Also based on the [Can AI scaling continue through 2030?](https://epoch.ai/blog/can-ai-scaling-continue-through-2030) it looks like that we will be able to scale AI training runs to 2030. At the moment it looks like there is no major bottleneck apart from "AI is a bubble" burst - which might slow things down. But the "AI bubble" is just a course correction and is more about hype and investmenet promises made to investors not about the usefullness of this technology.

**AI is usefull and will transform the market**
So when the bubble pops and the dust settles - what will the market look like? I believe AI tools will become just that: _tools_, and the question is how will this transformation look like.

```ad-sidenote
_AI usefullness polarization_

The AI usefulness debate has two teams: "it's broken" and "engineers are dead." Both are wrong. AI is great at some problems, terrible at others. The interesting question is knowing which is which.
```
## Transformation - nothing new in IT

<div markdown="0">
{% include /ai-future/chart-demand.html %}
</div>

This is probably obvious, but the market is _constantly_ transforming. If you look at the employment history of software engineers in the US, you see steady growth with some bumps. It is easy to assume here that demand is growing, demand was always there and demand will continue. But this view hides a lof of complexity. The demand isn't for "software engineers" as a single monolithic entity or category it's for specific skills, and those do shift constantly. 

<div markdown="0">
{% include /ai-future/chart-languages.html %}
</div>

This can be observed in the popularity of programming languages - some do lose the usage and some gain it. The industry was dominated by Java, C and C++ and now Python is at the top - probably accounting for a lot of demand and a lot of demand in the `AI area`.

<div markdown="0">
{% include /ai-future/chart-emerging-skills.html %}
</div>

Similar picture does come up in the skills area - from Manual QA to Test Automation, Devops, DevSecOps. A lot of the current demand requires new types of skills that we had to acquire in time.

<div markdown="0">
{% include /ai-future/chart-metodologies.html %}
</div>

And last chart methodologies - once we were dominated by waterfall which then change to agile and scrum.

Based on that if we look at the Supply and Demand chart a new picture emerges one that is telling a story of shifts in the industry and pople requiring to acquire new skills.

## Why does transformation happen? Competition → Commoditisation → Innovation
Transformation isn't unique to tech. It's core part of our economic model and arguably part of being human. We evolved in a competitive environment, under constant pressure from natural selection. That same pressure drove us toward collaboration, cooperation, and eventually organising ourselves into societies.  In the market conditions we are in a constant cycle of: **Competition -> Commoditization -> Innovation**

Here is what I mean: A company discovers a new need in the market, creates a product, this brings profit. Other companies see it and start competing. Competition drives down margins, and the product becomes commoditised - nothing special anymore. To escape low margins, you need to innovate. Find novel ideas. Create new value. And the cycle repeats.

```ad-sidenote
_What about `monopolies`?_
I know, I know - this is much more complicated and competition is not as clear. There are specific markets dominated by single companies (either whole segment of the market or geographically), and even in the past goverments had to interveene in order to open up the competition. 

One great example from my country was breaking up dominant telecomunications company in Poland to open up the market (which was very succesfull for the economy and the consumers).

But as a principle this still holds in my opinion.
```
### Software development was always under transformation pressure

Now, as software engineers, we might think this doesn't apply to us. We're engineers. Innovation was driven by engineers wanting to do things better, right? Some of it, sure. Open source is a perfect example of intrinsic motivation—people building better tools because they wanted better tools. But a lot of innovation, maybe most of it, was driven by the market.

**Software development has always been expensive.** Designing systems, writing code, testing, releasing to production - all of it costs time and money. But here's the thing: coding was never the _point_. The goal was always to build a product. Software development is a necessity, not the core reason we do any of this.

So the market - companies, individual engineers, entire communities - felt pressure or need to innovate. Bring the cost of development down. Make the work easier. And they did:
- New programming languages made it easier to write code
- Frameworks like the JVM handled memory management so we didn't have to
- Languages like Go and Erlang targeted concurrency as systems grew more complex
- Ruby and Python optimised for productivity and speed of delivery
- Agile innovated around the SDLC process
- Cloud made it simpler to orchestrate complex architectures without owning hardware
- DevOps emerged to bring engineers closer to infrastructure - but only after the cost of both coding and infrastructure engineering dropped enough, and complexity increased enough, to make it worthwhile

The pattern is clear: each wave of transformation abstracts away complexity and shifts where value is created. 

### The case of Manual -> Automated -> AI driven testing

<div markdown="0">
{% include /ai-future/chart-testing-transition.html %}
</div>

**Manual QA**  - Steady decline demand is dropping, skill becomes oversupplied. Red zone - too many people, not enough roles. The market stopped rewarding this skill.

**Test Automation** - Different story, steady increase in demand, supply lagging behind. Green zone - shortage, high value, opportunity. People who learned automation early rode that wave. 

**AI Testing** - is the new emerging skill. Right now: high demand, low supply. Another Green zone. Another window of opportunity. Higher impact on Manual QA as AI agent testing will target this area heavilly.

The pattern repeats:
1. New skill emerges → undersupplied → high value
2. People learn new skills → supply grows → value normalises
3. Next shift arrives → previous skills lose steam

## Transformation creates a window of opportunity

Every paradigm shift follows a pattern. Early adopters get in, figure out the new tools, and unlock productivity gains before everyone else. That head start translates to outsized value on the market.

But this boost doesn't last. As adoption spreads, best practices develop, tooling matures, and what was once an edge becomes the baseline. The window closes. What felt like a superpower becomes just "how things are done."

We're in that window right now.

The market has always rewarded people who invest early and take risk. Not reckless risk—calculated bets on where things are heading. The engineers who leaned into cloud early, who adopted DevOps before it was a job title, who bet on mobile when it was still "nice to have"—they rode the wave up.

I believe AI will transform our industry. It will make us more productive, more impactful, and ultimately more rewarded by the businesses we work for. But to benefit from this shift, you'll need to transform yourself. You'll need to become a different type of engineer.

AI is and will be an opportunity for the whole industry. But there will be people who benefit from it and people who won't. I'm not saying jobs will disappear—I don't think that's the case. What _will_ shift is the value of different roles and the types of skills you bring. Some skills will appreciate. Some will depreciate. The question is which side you're on.
 
```ad-note
_IT is in a pole position_

Being in tech means you're in pole position to see what's coming. We're one of the first industries adopting AI at scale. That puts us in the early adopter bracket of a technology shift that will eventually hit every industry. A lot of sectors will face this challenge in 5–10 years. By then, we'll have already lived through it and experienced it, which will open doors to many places not only related to Tech/IT.
```

<div markdown="0">
{% include /ai-future/chart-system-thinking.html %}
</div>

---
layout: d3post
title: Software Engineer 2026 Transformation
date: 2025-12-30 07:00
author: Michal Franc
comments: true
categories: [Career]
tags: [ai, career]
image: logo_ai_2026.png
series:
permalink: /blog/ai-2026/
summary: AI 2026 Software Engineering career transformation
---
```ad-quote
_Roy Amara_
We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.
[Wikipedia](https://en.wikipedia.org/wiki/Roy_Amara)
```

The changes that are now happening in the IT industry with the AIs and LLMs are so significant that I find myself repeating myself in various groups and places so I will just write down my thoughts here so I can share them publicly. 

First thing first: **I have no idea where we are heading exactly - I am only like 75% sure.** There is still a lot of uncertainty but I think at the end of 2026 we will have 95% of the picture clear. I have my bets and opinions but take them with caution as a lot can change in 2026. The pace of innovation is super fast right now.

```ad-tldr
Software Engineering is not going anywhere. The industry is facing a huge transformation right now. This is not the first transformation, this industry is changing constantly. However this will be a different one, that is a bit scary but also exciting.

Fundamentally it won't change our relationship to work - we were always doing the work to solve problems and deliver value. But it will change what is considered a valuable skill, how work gets done, and where the opportunities are.

The winners of this change will be the people that can figure out which parts of the Software Engineering job won't be commoditised by AI. My bet is centered around: domain expertise, system design, product oriented development and understanding of the business.
```
## There are 3 AI camps.

**We are Doomed.**
In this scenario, I’m assuming we reach AGI and AI simply replaces us. But looking at recent evaluations, like [METR’s assessment of OpenAI’s GPT-5.1-Codex-Max](https://evaluations.metr.org/gpt-5-1-codex-max-report/#summary), current LLM systems are still incapable of generating serious problems for us. And if we look at benchmarks like [ARC Prize](https://arcprize.org/), we’re still far, far away from reaching AGI, at least based on the way we currently measure what AGI is. Based on [AI 2027,](https://ai-2027.com/) there is also a scenario that we have paradise enabled by AI, but it also implies that the industry as a whole is `gone`.

**AI is a fad that will fail.**
In the past, there were two major [AI winters](https://en.wikipedia.org/wiki/AI_winter). It is possible that another one is just around the corner.  There are already experts who argue that LLMs are not AI and are going to take us nowhere. That the path to AGI requires more breakthroughs. I can’t argue with that, as I am not an expert in this field all I am interested in is on how to use the current generation of AI/LLMs in my field of expertise.

I think we’re long past the point where we can assume that AI is a failure. Based on my experience and people around me, there is a lot of utility and value in the current generation of LLMs. I don’t think anyone will argue about that. The discussions in my circle are more about - how to use it? What are the good  practices? What will be the new design patterns we should adapt to?

Also, based on the [Can AI scaling continue through 2030?](https://epoch.ai/blog/can-ai-scaling-continue-through-2030) It looks like we will be able to scale AI training runs to 2030. At the moment, it looks like there is no major bottleneck apart from the “AI is a bubble” burst, which might slow things down. But the “AI bubble” is just a course correction and is more about hype and investment promises made to investors not about the usefulness of this technology.

**AI is useful and will transform the market**
So when the bubble pops and the dust settles - what will the market look like? I believe AI tools will become just that: `tools`, and the question is, how will this transformation look like.

```ad-sidenote
_AI usefullness polarization_

The AI usefulness debate has two teams: "it's broken" and "engineers are dead." Both are wrong. AI is great at some problems, terrible at others. The interesting question is knowing which is which.

There are also risks around opening ourselves up to accepting that it is ok that we don't fully understand what has been generated and why.[The Normalization of Deviance in AI](https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/)
```
## Transformation - nothing new in IT

<div markdown="0">
{% include /ai-future/chart-demand.html %}
</div>

This is, of course, obvious, but the market is `constantly changing`. If you look at the overall employment history of Tech related roles in the US, you see roughly a steady growth. I couldn't find exact data for software engineers, but these roles did follow a similar curve.

Based on this chart, we can assume that demand is growing constantly. But this view hides a lot of complexity. Defining what the "software engineering" role is, is simple when we think about generic terms like building software. But uderneath when we think about programming languages, specific skills or practices used in this field, the view gets a lot more complicated.

What the market actually demands shifts constantly.

### Programming Languages
<div markdown="0">
{% include /ai-future/chart-languages.html %}
</div>

This shift can be observed in programming language popularity. The [TIOBE index](https://www.tiobe.com/tiobe-index/) shows how languages rise and fall over time. The industry was once dominated by Java, C, and C++. Now Python sits at the top - likely driven by demand in data science and AI.

The growing demand is spread across different programming languages needs based on market needs.

**My personal experience:**  The first language I have used commercially at work was JavaScript with JQuery (old times). Then I moved to C# / .NET world for a couple of years.  There was some time with more of JavaScript (Angular/Reac), and I moved to write software in Golang, Java, Python, or even Lua. I also spent multiple years writing HCL (Terraform). These days, I mostly write code in C#, Golang and Python.

```ad-sidenote
_TIOBE index vs PYPL index_

I know TIOBE is only one opinionated way to measure programming language usage. Other approaches like [PYPL](https://pypl.github.io/PYPL.html) sometimes show different data. But both tell the same story: language popularity is fluid. What dominates today won't necessarily dominate tomorrow.
```

### Emerging Skills 
<div markdown="0">
{% include /ai-future/chart-emerging-skills.html %}
</div>

A similar picture does come up in the skills area - from Manual QA to Test Automation, DevOps, and DevSecOps. A lot of the current demand requires new types of skills that we had to acquire over time.

**My personal experience:** I have started as SharePoint Developer long time ago, then I jumped into fullstack ASP.NET world. I was a huge advocate of TDD. As the industry changed, I was an early adopter of Docker and the cloud. Even thought i spent a lot of time in C# oriented companies, I have never used Azure but AWS. With time, I discovered the beautiful world of distributed systems and I focused more on DevOps/SRE oriented work. Today, I would consider myself to be a generalist.

### Methodologies
<div markdown="0">
{% include /ai-future/chart-metodologies.html %}
</div>

And last chart methodologies - once we were dominated by waterfall, which then change to agile and scrum.

**My personal experience:** I had the opportunity to try Waterfall (It wasn’t as bad as the current myths portray it). But I entered the market with already big ideas like DDD, Agile on the horizon, so it was easy to switch over to it.
## Why does transformation happen? Competition → Commoditisation → Innovation
Transformation isn’t unique to tech. It’s a core part of our economic model and arguably part of being human. We evolved in a competitive environment, under constant pressure from natural selection. That same pressure drove us toward collaboration, cooperation, and eventually organizing ourselves into societies.  In the market, we are in a constant cycle of: **Competition -> Commoditization -> Innovation.**

Here is what I mean: A company discovers a new need in the market, creates a product, and this brings profit. Other companies see it and start competing. Competition drives down margins, and the product becomes commoditised - meaning it is not special anymore. To escape low margins, you need to innovate. Find novel ideas to create new value. And the cycle repeats.

```ad-sidenote
_What about `monopolies`?_
I know, I know - this is much more complicated, and competition is not as clear. There are specific markets dominated by single companies (either a whole segment of the market or geographically), and even in the past goverments had to interveene in order to open up the competition as Big players always have an incentive to control competition and the market itself.

One great example from my country was breaking up the dominant telecommunications company in Poland to open up the market (which was very successful for the economy and the consumers).

But as a principle, competition as one of the main market drivers in general still holds.
```
### Software development was always under transformation pressure.
Now, as software engineers, we might think this doesn’t apply to us. We are engineers, and all of the transformations were driven by innovation and people wanting to do things better. Some of it, sure. Open source is a perfect example of people building better tools because they wanted better tools. But a lot of innovation was driven by the market.

**The software development process has always been expensive and was considered to be a pain point to get around.** Designing systems, writing code, testing, releasing to production - all of it costs time and money, while the specifics of building software was never the *point*. The goal was always to build a product. Software development was a necessary cost to get there.

The market - companies, individual engineers, entire communities - felt pressure or a need to innovate to bring the cost of development down. Make the work easier:
- New programming languages made it easier to write code.
- Frameworks like the JVM handled memory management, so we didn’t have to
- Languages like Go and Erlang targeted concurrency as systems grew more complex.
- Ruby and Python are optimized for productivity and speed of delivery.
- Agile innovated around the SDLC process.
- Cloud made it simpler to orchestrate complex architectures without owning hardware.
- DevOps emerged to bring engineers closer to infrastructure - but only after the cost of both coding and infrastructure engineering dropped enough, and complexity increased enough, to make it worthwhile.

This was a difficult truth for me to accept. As an engineer, I wanted to believe the craft itself mattered. It took me some time to realize that the market doesn’t care about Software Craftsmanship or how elegant the code is. Of course, this doesn’t mean that we can just YOLO with software development, but there is a term I like to use called **Good Enough Software** that puts a lot more pressure on Engineering Talent to decide how to develop software in a scalable, maintainable, sustainable way - depending on the context - market, product, and organisation you are in.
### The case of Cloud, Kubernetes - abstracting away complexity

What also emerges from these transformations is that each wave abstracts away complexity and shifts where value is created.

Cloud and Kubernetes are good examples here. Initially, only the biggest companies could build truly scalable, global products. They had the resources, expertise, and infrastructure to do it. But as internet usage grew, more companies wanted the same capabilities. AWS capitalized on this - opening up their way to do it in the form of the cloud. But the complexity of these systems kept growing. It still wasn’t easy to make them reliable and scalable. So the market responded again: orchestration systems emerged to manage the chaos. And then we got Kubernetes.

I know - Kubernetes is complex. It’s not “easy.” It’s sometimes overused. But here’s what it did: it commoditised the ability to build global, scalable, reliable systems. What was once the domain of really Big Companies became accessible to a much broader market. **This shifted where the hard problems lived - and where the value was created.**

This also commoditised the skills needed to build global systems. But the demand was there, so it created an opportunity. If you were willing to learn, you could capitalise on the shift. The market rewarded those who adapted. This change also actually opened up the need for a new type of skills to a wider market.

### The case of Manual -> Automated -> AI driven testing

<div markdown="0">
{% include /ai-future/chart-testing-transition.html %}
</div>

When I joined the industry, it was typical for testing to be done by a dedicated role. You had developers and you had testers with two different jobs and clear responsibilities. Then a change happened and the org I was part of, Manual QAs, decided to learn programming. This also meant that programmers were told to get better at testing. Microsoft formalized this with the SDET role (Software Development Engineer in Test), explicitly encouraging the move toward automated testing. Eventually, even that role disappeared - absorbed into the broader Software Engineer title.

The organisations I worked with for the last 12+ years didn’t have a dedicated testing role at all. Testing has become a part of Software Engineering and someones specialty, expertise, but not the only thing.

The chart presents here the **Manual QA**  skill in a steady decline. Demand dropped, supply didn’t adjust, and the skill became oversupplied. Which led to a drop in value generated by this specific skill. **Test Automation,** on the other hands paints a completely different picture with value generated out of this skill growing through the years.

**LLMs** will likely transform this area further - but here’s the paradox. Manual QAs may actually be better positioned to benefit from it than test automation engineers. Why? Because the *automation* part of the skill is exactly what AI will commoditise. What remains valuable is the domain expertise, the attention to detail, the ability to identify what needs testing in the first place. If Manual QAs adopt AI-enabled test development, their skills will complement the LLMs usage rather than compete with it.

A simple pattern that appears here is:

1. New skill need  emerges → is under supplied → generate high value.
2. People learn new skills → supply grows → value normalizes.
3. Next shift arrives → previous skills demand lose steam -> and you need to adapt.

## Transformation is an opportunity (+ stress and uncertainity)

There are two ways to approach transformation. You can treat it as a risk - a threat to your ability to generate value, a force that might make your skills obsolete. Or you can look at it as an opportunity. I prefer to look at it from an opportunity angle.

Of course its not easy to just say - well, adapt - learn new skills. I am almost 40, and I don’t have the same energy that I had in my 20s. By saying `just treat is as an opportunity,` I’m not being an asshole or a smart-ass. I really do understand this is stressful. It’s not easy to just “adapt” or “learn new skills” when you’ve spent years building expertise that suddenly can potentially become less valuable or no longer a thing that differentiates you in the market. But I don’t think there is anything else we can do about it. The market will just do its own thing - and force us to transform.

This opportunity is also a bit `fragile` as usually its the early or late adopters that start using new practices or skill and unlock new productivity or value before everyone else. This boost doesn’t last for long. Adoption spreads, best practices develop, tooling matures, and what was once a new thing becomes the baseline.

It can also be risky, as when you are an early adopter, you have no idea if this specific new wave or hype will stay and develop to something more serious. The amount of innovation and changes that are happening now around AIs and LLMs makes it difficult to decide if its stable or worthy en devour. Personally, my instinct tells me AI is here to stay and will be a huge trans formative factor, so I need to keep up. But the market has always rewarded people who take a risk. Not reckless risk - a calculated one.

```ad-sidenote
_You should always have some risky bets in your career_  

Think of it like investing. You diversify. Some skills you go deep on, hands-on. Others you keep an eye on, waiting for the right moment to commit. Not every bet pays off—but having no risky bets at all is the riskiest position of all.
```

**I believe AI will transform our industry. It will make us more productive, more impactful, and ultimately more rewarded by the businesses we work for. But to benefit from this shift, you’ll need to transform yourself. You’ll need to become a different type of engineer.** 
```ad-sidenote
_IT is in a pole position_

Being in tech means you're in pole position to see what's coming. We're one of the first industries adopting AI at scale. That puts us in the early adopter bracket of a technology shift that will eventually hit every industry. A lot of sectors will face this challenge in 5–10 years. By then, we'll have already lived through it and experienced it, which will open doors to many places not only related to Tech/IT.
```

## AI / LLMs transformation

Before we can jump into some conclusions or advice's on how the next transformations might look like, lets get some things straight first.
### Software engineering was never only about coding

<div markdown="0">
{% include /ai-future/chart-system-thinking.html %}
</div>

Code was always a tool, a way to orchestrate `0s` and `1s` to fulfill business needs - not the goal in itself. Software engineering has always been about building things and solving problems that humans face. All economic activity is ultimately driven by what human need, our job is to figure out and build systems to provide for this need.

The early career model from the past put a lot of emphasis on coding and computer science. This skill-set was usually the first step on the ladder and one of the main reasons engineers of my generation got hired for. But along the way Software Engineering role has become a lot more than just writing code or obsessing about algorithms.

These days, there is a lot of time spent on designing systems, figuring out trade-offs, communicating with stakeholders and team members or even customers. You need to plan the work and advocate for features or changes. You can also get involved in changing the processes or guidelines for the rest of the team. A significant amount of time is spent reviewing code or ideas. We also need to spend time figuring out how to be effective in the organisation - every company is usually different and has a different culture that you need to adapt to.

The job was always bigger than just writing code. And `this is great news, it means Software Engineering will not disappear`.

The bottleneck of software engineering of tomorrow will move up. Thanks to AI and LLMs, coding will no longer be the limiting factor. But that doesn’t mean it’s smooth sailing from here - it just means that we will hit new (or old) constraints with higher force and frequency.

The ability to frame and decompose problems will become the new limiting factor. Same with maintaining product quality, reviewing changes, navigating operational constraints, and understanding your organisational context and requirements. All of this will still require a human engineer to deal with.

AI and LLMs reward precise intent and clarity. Vague input produces vague output.

```ad-sidenote
_Autocomplete didn't make us 10x productive_
I remember when autocomplete was becoming popular. There was this feeling that we'd all become much more productive. But it turned out it was not the case. There were benefits, but autocomplete was was not as transformative as a lot of people thought. It has helped us with just part of the day-to-day work.
```

###  The core of software engineering was always about delivering value
It is just that there was a time when we could pretend it was not.

I remember the `golden age of my coding-focused engineering career`.  I could happily code and code and only code. Everything else was handled by the organisation. The business analyst prepared a huge spec, the scrum master or EM created tickets - all I would do is just get the ticket code, leave it for the tester, and jump into another ticket.

From this Point Of View, it kind of looked like my job is about `coding`, but behind the scenes, someone else was translating my work to actual value delivery. As I grew and joined more product-oriented companies, I started doing more and more tasks not only related to `coding` and getting involved in a whole spectrum of tasks required to build successful product.

I think the AI and LLMs will serve as a great equalizer here and will force a lot more engineers to start thinking about all the different tasks and skills they never had to think about before. This is one of the things I have noticed in US Big Techs - push towards - it's your responsibility to understand what kind of impact and value you bring to the table.

Recently, I noticed that this mindset is spreading across the IT community. People see that this is probably the change that will happen. Software Engineers are becoming more than just technically focused team members. Being involved in business, product, and whole spectrum of activities. No longer just translators of someone else's vision but partners and drivers of the vision itself.

The good thing is that - with this mindset, these people will be able to generate even more vaule and impact and will be rewarded for it handsomely.
## OK Michal - so much talk - get to the point - what should I Do?
Yeah, that is a question, the main one, that we will  need to find an answer to in 2026.

**To be honest, don't listen to me you have to kind of figure it out for yourselve and adapt it to your career and context.** But if you are interested to check what I am planning to do or what I would do - keep on reading.
### Beyond Hard Skills
<div markdown="0">
{% include /ai-future/chart-skill-progression.html %}
</div>

I really love this chart from Alex Ewerlöf. It helped me a lot when thinking about the choices I should be making in my career.  
  
Investment in hard skills at some point reaches a moment of diminished returns. To be fully clear, it doesn't mean you should ignore it completely. I still do it, you still need to keep an eye out for emerging trends and approaches. Try out tools, new languages. But for instance, learning Java to the book if you already know C# - does it make a difference? I don't think so.

AI and LLMs will also bridge the hard skill gap across languages and frameworks. The specific flavor you know - .NET, Java, Python - will matter less and less. Marketing yourself as "I'm a .NET Engineer" or "I'm a Java Engineer" is probably not going to be an effective strategy going forward. The market will care less about _what_ you can code in, and more about _what problems you can solve,_ and _what value you can deliver_ and what is your _expertise_ (more on this later).

So maybe it's time to spend more time building Soft and Business Skills as they will provide more value and substance in the work you do.

I also encourage reading this serie from Alex:
- [Senior to Staff Engineer - Alex Ewerlöf Notes](https://blog.alexewerlof.com/p/senior-engineer-to-staff-engineer)
- [Beyond Staff Engineer - Alex Ewerlöf Notes](https://blog.alexewerlof.com/p/beyond-staff-engineer)
- [Principal Engineer - Alex Ewerlöf Notes](https://blog.alexewerlof.com/p/principal-engineer)

```ad-sidenote
_LLMs will not make Hard Skills Obsolete_

This is an important point to make. I don't think hard skills will go away even with AI and LLMs. In order to properly work with AI, you still need to understand foundational knowledge (Algorithms and Data Structures, Distributed Systems). Learn at least one programming language and different paradigms of programming. Build a lot of projects, solutions, and make a ton of mistakes. Only with that kind of knowledge and experience will you be able to use AI and LLMs correctly.

AI and LLMs are great when you ask correct questions or decompose problems into correct things - in order to do it you need hard skills.
```

### Foundational Engineering Knowledge
Another set of skills that I don’t think will go away is Software Engineering foundations.

This foundational knowledge enables crisp and intentional communication with AI agents. You’ll understand how to frame problems better, how to validate the output, and what kind of question to actually ask. Without it, the chance of ineffective prompting increases. So the more foundational knowledge you have, the more effective you will be when working with AI agents.

**Algorithms and data structures** are here to stay. But the knowledge that matters is not memoization of algorithms or the ability to  pass interviews (it is now popular to frame this as for interview passing knowledge). What actually is important is getting an intution and understanding of tradeoffs mixed with real-world usages examples.

It is much more easier to reason about database engines and indexees when you know  the basics of self balancing trees like B-trees. Another example: HyperLogLog. You’ll hit rough edges using ElasticSearch if you don’t understand probabilistic data structures. Another: vector databases. Understanding how they work makes it much easier to figure out what’s happening behind the scenes with LLMs and all their “magic”.

**Distributed Systems and System Design.** This knowledge helps you understand how to build complex systems - and what is even more important, what physical limitations we cannot cross (in our universe), no matter how beautiful our solution is or how clever the design is.

Understanding CAP theorem and PACELC helps you build a simple (or maybe a bit complex) mental model on the tradeofs available to us as engineers and how to reason about them. ACID vs non-ACID helps you figure out why NoSQL databases appeared and when to probably use them.

Similarly, you won’t fully grasp the importance of load balancing, fault tolerance, or what a transaction actually is and why it matters - without understanding the theory. Same with consensus algorithms like Paxos and Raft, or concepts like leader election. They’re the foundation of every reliable system you’ll ever build or work with.

Without this knowledge, it will be much more difficult for you to understand how to design systems that are durable, available, and scalable. AI agents will easily fool you and set you on a path that will not lead to an optimal solution and basically waste your time - assuming you even know what questions to ask in the first place.

And most importantly, without this knowledge, it will be much more difficult to reason about various trade-offs. Which, frankly, is the most important skill for engineers. I mean answering the question, what is a `good enough` system we should build give our context, domain, market, budget, and team. And how to reason about it, make a decision, and then sell this decision to everyone else.

Example of potential things to read and learn from:
- [Distributed systems for fun and profit](https://book.mixu.net/distsys/single-page.html)  
	Basic but great overview - a good starting point.
- [Database Internals](https://www.databass.dev/)  
	A lot of details - but if you want to understand how the Database Engines work - I think it is one of the best resources right now.
- [Raft](https://thesecretlivesofdata.com/raft/)  
	Great visualization of RAFT and distributed consensus.
- [Designing Data-Intensive Applications (DDIA) ](https://dataintensive.net/)  
	Great book - which for me is like a road-map. The book itself is not really comprehensive, but it provides a great starting point plus is full of references that you can use to learn more. For me its like a `map` of reading about how to build complex systems.

```ad-sidenote
_AI agents and code commoditization will lead to increased complexity._

As with every transformation - ease of doing things on one layer will lead to explosion of complexity in a layer above it. 

Demand for foundatiional knowledge around distributed system and system design will be a lot higher than now.
```

```ad-warning
Punctuation pass and spellcheck done to this point!!
```

### Domain expertise

#### TODO: expand on it
- what we need and why
- making decisions
- understanding decision where they are coming from understanding business

This is my main proposition: to benefit from this AI transformation, you need to be more than just a technologist who writes code, creates solutions, and designs architecture. You need to be a **partner to your business, your company, and your colleagues**. You need to be a driving factor behind revenue and value creation.

You can no longer be the "magic box" that simply translates someone else's ideas into technical solutions. You need to understand and drive the business outcomes yourself.

```ad-quote
The real value of a developer is knowing good process design on a holistic level that goes into an app and being able to work with the business people to make their vision a reality. AI cannot do that. It can code stuff, but it's "garbage in, garbage out" if you don't really know what you really want. And most business people have a good idea but need coaxing by a fellow human to truly make it a reality. AI can help code your functions and stuff, but it sucks at the big picture side of the house.
```

_This isn't a new idea—Eric Evans preached this in his Domain-Driven Design book years ago. We just need to get back to this foundation._
### System Quality / Verification
#### TODO: expand
- correctness
### System Design
#### TODO: expand
- tradeoffs
### Impact Outcome orientation
#### TODO: expand
In my opinion, we will need to become more focused on **business impact and outcomes**. We can no longer be engineers who just do magic tricks with code and technology without fully understanding where the impact lies.
### Becoming AI Native
#### TODO: expand / 1 more pass
As 40 years old engineer this is important point to make for me. I have experience, knowledge. I have build things in some specific way, I acknoweledge the fact that after soo many years in industry I like to do things in specific way (I use vim everyday I despise working without i3wm and proper Linux setup). 

So it will be important for me to challenge my habbits and current `neural network structure` I have in my brain. I just barerly feel like I am treating AI tools naturally and not as novelty, nice to have thing or skill.

The way I did it is I forced myself to use AI and LLMs even if my brain was suggesting to me its not productive or a waste of time, or results are bad. With time I started noticing the way and patterns on how to get better results and this now servers a s reainforcment mechanism - i see benefits i learn more of it - i use it more - i get more familar and natural with it.

Don't get discouraged here - the hype is real - there is a lot of value behind AI and LLMs - you just need to keep moving on.

## Summary
